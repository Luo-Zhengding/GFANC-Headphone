{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36172a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import librosa\n",
    "import socket\n",
    "\n",
    "\n",
    "class STFT_Feature:\n",
    "    def __init__(self, sample_rate=13000, n_fft=1024, hop_length=512, n_mel=64):\n",
    "        self.transformation = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mel)\n",
    "\n",
    "\n",
    "def minmaxscaler(data):\n",
    "    return (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "\n",
    "class Control_filter_Index_predictor:\n",
    "    def __init__(self, MODEL_PATH):\n",
    "        from Simple_ShufflenetV2 import Modified_ShufflenetV2\n",
    "        self.model = Modified_ShufflenetV2(num_classes=7)\n",
    "        self.model.load_state_dict(torch.load(MODEL_PATH))\n",
    "        self.model.eval()\n",
    "        self.feature_extractor = STFT_Feature(sample_rate=13000, n_fft=1024, hop_length=512, n_mel=64)\n",
    "\n",
    "    def predict_ID(self, noise):\n",
    "        noise = minmaxscaler(noise)\n",
    "        noise = self.feature_extractor.transformation(noise)\n",
    "        noise = librosa.core.power_to_db(noise)\n",
    "        noise = torch.from_numpy(noise).unsqueeze(0)\n",
    "        prediction = self.model(noise)\n",
    "        fre_ID = torch.argmax(prediction).item()\n",
    "        return fre_ID\n",
    "\n",
    "\n",
    "class UDP_pxie_connector:\n",
    "    def __init__(self, IpAddress, Port):\n",
    "        self.serverAddressPort = (IpAddress, Port)\n",
    "        self.UDPClientSocket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "\n",
    "    def send_message(self, text):\n",
    "        bytesToSend = str.encode(text)\n",
    "        self.UDPClientSocket.sendto(bytesToSend, self.serverAddressPort)\n",
    "\n",
    "\n",
    "class AudioRecorder:\n",
    "    def __init__(self, seconds=1, chunk=1000, sample_format=pyaudio.paInt24, channels=1, fs=13000, input_device_index=1):\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(format=sample_format, channels=channels, rate=fs, frames_per_buffer=chunk, input=True, input_device_index=input_device_index)\n",
    "        self.fs = fs\n",
    "        self.chunk = chunk\n",
    "        self.seconds = seconds\n",
    "        self.channels = channels\n",
    "        self.sample_format = sample_format\n",
    "    def record(self, filename):\n",
    "        frames = []\n",
    "        for i in range(0, int(self.fs / self.chunk * self.seconds)):\n",
    "            data = self.stream.read(self.chunk)\n",
    "            frames.append(data)\n",
    "        self.stream.stop_stream()\n",
    "        self.stream.close()\n",
    "        self.p.terminate()\n",
    "        wf = wave.open(filename, 'wb')\n",
    "        wf.setnchannels(self.channels)\n",
    "        wf.setsampwidth(self.p.get_sample_size(self.sample_format))\n",
    "        wf.setframerate(self.fs)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "        wf.close()\n",
    "        waveform, sample_rate = torchaudio.load(filename)\n",
    "        return waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb86d8-291a-41d8-bc91-ab831eccf384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
