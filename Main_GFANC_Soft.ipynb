{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7720a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import torch\n",
    "import socket\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "\n",
    "def minmaxscaler(data):\n",
    "    return (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "\n",
    "class STFT_Feature:\n",
    "    def __init__(self, sample_rate=13000, n_fft=1024, hop_length=512, n_mel=64):\n",
    "        self.transformation = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mel)\n",
    "\n",
    "\n",
    "class Soft_weights_predictor:\n",
    "    def __init__(self, MODEL_PATH):\n",
    "        from Simple_ShufflenetV2 import Modified_ShufflenetV2\n",
    "        model = Modified_ShufflenetV2(num_classes=6)\n",
    "        model.load_state_dict(torch.load(MODEL_PATH))\n",
    "        model.eval()\n",
    "        self.model = model\n",
    "        self.feature_extractor = STFT_Feature(sample_rate=13000, n_fft=1024, hop_length=512, n_mel=64)\n",
    "\n",
    "    def predict_weights(self, noise):\n",
    "        global soft_labels_pre\n",
    "        noise = minmaxscaler(noise)\n",
    "        noise = self.feature_extractor.transformation(noise)\n",
    "        noise = librosa.core.power_to_db(noise)\n",
    "        noise = torch.from_numpy(noise).unsqueeze(0)\n",
    "        soft_labels_now = self.model(noise).squeeze()\n",
    "        return Compare_now_pre(soft_labels_now.detach().numpy())\n",
    "\n",
    "\n",
    "def Compare_now_pre(soft_labels_now):\n",
    "    global soft_labels_pre\n",
    "    # L2范数\n",
    "    if np.linalg.norm(soft_labels_now - soft_labels_pre) / np.linalg.norm(soft_labels_pre) >= 0.3:  # Update threshold\n",
    "        soft_labels_pre = np.round(soft_labels_now, 1)\n",
    "        return soft_labels_pre\n",
    "    return None\n",
    "\n",
    "\n",
    "def UDP_sender(message, ip, port):\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "    try:\n",
    "        sock.sendto(message.encode(), (ip, port))\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        sock.close()\n",
    "\n",
    "        \n",
    "class AudioRecorder:\n",
    "    def __init__(self, seconds=1, chunk=1000, sample_format=pyaudio.paInt24, channels=1, fs=13000, input_device_index=1):\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(format=sample_format, channels=channels, rate=fs, frames_per_buffer=chunk, input=True, input_device_index=input_device_index)\n",
    "        self.fs = fs\n",
    "        self.chunk = chunk\n",
    "        self.seconds = seconds\n",
    "        self.channels = channels\n",
    "        self.sample_format = sample_format\n",
    "    def record(self, filename):\n",
    "        frames = []\n",
    "        for i in range(0, int(self.fs / self.chunk * self.seconds)):\n",
    "            data = self.stream.read(self.chunk)\n",
    "            frames.append(data)\n",
    "        self.stream.stop_stream()\n",
    "        self.stream.close()\n",
    "        self.p.terminate()\n",
    "        wf = wave.open(filename, 'wb')\n",
    "        wf.setnchannels(self.channels)\n",
    "        wf.setsampwidth(self.p.get_sample_size(self.sample_format))\n",
    "        wf.setframerate(self.fs)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "        wf.close()\n",
    "        waveform, sample_rate = torchaudio.load(filename)\n",
    "        return waveform, sample_rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
